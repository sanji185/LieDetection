{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ae7dfc",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a6dc7",
   "metadata": {},
   "source": [
    "# 2. Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE=[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "# right eyes indices \n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "LEFT_IRIS = [474,475, 476, 477] \n",
    "RIGHT_IRIS = [469, 470, 471, 472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1092a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh # FaceMesh Model\n",
    "#mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)   # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                     # Image is no longer writeable\n",
    "    results = model.process(image)                    # Make prediction\n",
    "    image.flags.writeable = True                      # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)    # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_face_mesh.)\n",
    "    mp_drawing.draw_landmarks(image, results.face_irises, mp_face_mesh.FACEMESH_IRISES)\n",
    "    mp_drawing.draw_landmarks(image, results.face_faceoval, mp_face_mesh.FACEMESH_FACE_OVAL)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb235e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set mediapipe model\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces =1,\n",
    "    refine_landmarks = True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        # Make Detections\n",
    "        image , results = mediapipe_detection(frame,face_mesh)\n",
    "        print(results)\n",
    "\n",
    "        # Draw landmarks\n",
    "        #draw_landmarks(image,results)\n",
    "        \n",
    "\n",
    "\n",
    "        # Show to Screen\n",
    "        cv2.imshow('OpenCV feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        k = cv2.waitKey(30) & 0xff # press ESC to exit\n",
    "        if k == 27 or cv2.getWindowProperty('OpenCV feed', 0)<0:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "map_face_mesh = mp.solutions.face_mesh\n",
    "# Set mediapipe model \n",
    "with map_face_mesh.FaceMesh(min_detection_confidence =0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # starting time here \n",
    "    start_time = time.time()\n",
    "    # starting Video loop here.\n",
    "    while True:\n",
    "        frame_counter +=1 # frame counter\n",
    "        ret, frame = camera.read() # getting frame from camera \n",
    "        if not ret: \n",
    "            break # no more frames break\n",
    "        #  resizing frame\n",
    "        \n",
    "        frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "        frame_height, frame_width= frame.shape[:2]\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "        results  = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_coords = landmarksDetection(frame, results, False)\n",
    "            ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "            # cv.putText(frame, f'ratio {ratio}', (100, 100), FONTS, 1.0, utils.GREEN, 2)\n",
    "            utils.colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, utils.PINK, utils.YELLOW)\n",
    "\n",
    "            if ratio >5.5:\n",
    "                CEF_COUNTER +=1\n",
    "                # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Blink', FONTS, 1.7, (int(frame_height/2), 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "\n",
    "            else:\n",
    "                if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                    TOTAL_BLINKS +=1\n",
    "                    CEF_COUNTER =0\n",
    "            # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "            utils.colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n",
    "            \n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "\n",
    "            # Blink Detector Counter Completed\n",
    "            right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "            left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "            crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "            # cv.imshow('right', crop_right)\n",
    "            # cv.imshow('left', crop_left)\n",
    "            eye_position, color = positionEstimator(crop_right)\n",
    "            utils.colorBackgroundText(frame, f'R: {eye_position}', FONTS, 1.0, (40, 220), 2, color[0], color[1], 8, 8)\n",
    "            eye_position_left, color = positionEstimator(crop_left)\n",
    "            utils.colorBackgroundText(frame, f'L: {eye_position_left}', FONTS, 1.0, (40, 320), 2, color[0], color[1], 8, 8)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # calculating  frame per seconds FPS\n",
    "        end_time = time.time()-start_time\n",
    "        fps = frame_counter/end_time\n",
    "\n",
    "        frame =utils.textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n",
    "        # writing image for thumbnail drawing shape\n",
    "        # cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n",
    "        cv.imshow('frame', frame)\n",
    "        key = cv.waitKey(2)\n",
    "        if key==ord('q') or key ==ord('Q'):\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "    camera.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf283e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79480f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_styled_landmarks(frame, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f883a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd70037",
   "metadata": {},
   "source": [
    "# 3. Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b26f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = []\n",
    "for res in results.face_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.x, res.visibility])\n",
    "    face.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x , res.y , res.z, res.visibility] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*4)\n",
    "    return np.concatenate([face])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488db75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775dc732",
   "metadata": {},
   "source": [
    "# 5. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e950263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dfc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ac1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
