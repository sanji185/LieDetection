{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ae7dfc",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "52fa08e8",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "52fa08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 462, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 506, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 341, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
>>>>>>> 12a1c683bd0de3ac8038917e26e0d648056f9353
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 12a1c683bd0de3ac8038917e26e0d648056f9353
   "id": "189d38ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19292/1930388814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a6dc7",
   "metadata": {},
   "source": [
    "# 2. Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE=[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "# right eyes indices \n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "LEFT_IRIS = [474,475, 476, 477] \n",
    "RIGHT_IRIS = [469, 470, 471, 472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1092a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh # FaceMesh Model\n",
    "#mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)   # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                     # Image is no longer writeable\n",
    "    results = model.process(image)                    # Make prediction\n",
    "    image.flags.writeable = True                      # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)    # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_face_mesh.)\n",
    "    mp_drawing.draw_landmarks(image, results.face_irises, mp_face_mesh.FACEMESH_IRISES)\n",
    "    mp_drawing.draw_landmarks(image, results.face_faceoval, mp_face_mesh.FACEMESH_FACE_OVAL)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb235e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set mediapipe model\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces =1,\n",
    "    refine_landmarks = True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        # Make Detections\n",
    "        image , results = mediapipe_detection(frame,face_mesh)\n",
    "        print(results)\n",
    "\n",
    "        # Draw landmarks\n",
    "        #draw_landmarks(image,results)\n",
    "        \n",
    "\n",
    "\n",
    "        # Show to Screen\n",
    "        cv2.imshow('OpenCV feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        k = cv2.waitKey(30) & 0xff # press ESC to exit\n",
    "        if k == 27 or cv2.getWindowProperty('OpenCV feed', 0)<0:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "map_face_mesh = mp.solutions.face_mesh\n",
    "# Set mediapipe model \n",
    "with map_face_mesh.FaceMesh(min_detection_confidence =0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # starting time here \n",
    "    start_time = time.time()\n",
    "    # starting Video loop here.\n",
    "    while True:\n",
    "        frame_counter +=1 # frame counter\n",
    "        ret, frame = camera.read() # getting frame from camera \n",
    "        if not ret: \n",
    "            break # no more frames break\n",
    "        #  resizing frame\n",
    "        \n",
    "        frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "        frame_height, frame_width= frame.shape[:2]\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "        results  = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_coords = landmarksDetection(frame, results, False)\n",
    "            ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "            # cv.putText(frame, f'ratio {ratio}', (100, 100), FONTS, 1.0, utils.GREEN, 2)\n",
    "            utils.colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, utils.PINK, utils.YELLOW)\n",
    "\n",
    "            if ratio >5.5:\n",
    "                CEF_COUNTER +=1\n",
    "                # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Blink', FONTS, 1.7, (int(frame_height/2), 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "\n",
    "            else:\n",
    "                if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                    TOTAL_BLINKS +=1\n",
    "                    CEF_COUNTER =0\n",
    "            # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "            utils.colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n",
    "            \n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "\n",
    "            # Blink Detector Counter Completed\n",
    "            right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "            left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "            crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "            # cv.imshow('right', crop_right)\n",
    "            # cv.imshow('left', crop_left)\n",
    "            eye_position, color = positionEstimator(crop_right)\n",
    "            utils.colorBackgroundText(frame, f'R: {eye_position}', FONTS, 1.0, (40, 220), 2, color[0], color[1], 8, 8)\n",
    "            eye_position_left, color = positionEstimator(crop_left)\n",
    "            utils.colorBackgroundText(frame, f'L: {eye_position_left}', FONTS, 1.0, (40, 320), 2, color[0], color[1], 8, 8)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # calculating  frame per seconds FPS\n",
    "        end_time = time.time()-start_time\n",
    "        fps = frame_counter/end_time\n",
    "\n",
    "        frame =utils.textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n",
    "        # writing image for thumbnail drawing shape\n",
    "        # cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n",
    "        cv.imshow('frame', frame)\n",
    "        key = cv.waitKey(2)\n",
    "        if key==ord('q') or key ==ord('Q'):\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "    camera.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf283e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79480f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_styled_landmarks(frame, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f883a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd70037",
   "metadata": {},
   "source": [
    "# 3. Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b26f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = []\n",
    "for res in results.face_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.x, res.visibility])\n",
    "    face.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x , res.y , res.z, res.visibility] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*4)\n",
    "    return np.concatenate([face])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488db75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775dc732",
   "metadata": {},
   "source": [
    "# 5. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e950263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dfc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ac1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
