{
 "cells": [
  {
<<<<<<< HEAD:Test2Try.ipynb
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed7676eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/662272548.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pygame \n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8af6555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 462, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 506, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 341, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39366c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40abf51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK = (0,0,0)\n",
    "WHITE = (255,255,255)\n",
    "BLUE = (255,0,0)\n",
    "RED = (0,0,255)\n",
    "CYAN = (255,255,0)\n",
    "YELLOW =(0,255,255)\n",
    "MAGENTA = (255,0,255)\n",
    "GRAY = (128,128,128)\n",
    "GREEN = (0,255,0)\n",
    "PURPLE = (128,0,128)\n",
    "ORANGE = (0,165,255)\n",
    "PINK = (147,20,255)\n",
    "points_list =[(200, 300), (150, 150), (400, 200)]"
=======
   "cell_type": "markdown",
   "id": "311899ed",
   "metadata": {},
   "source": [
    "# _Import and Install Dependencies"
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 3,
   "id": "9296272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables \n",
    "frame_counter =0\n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "counter_right=0\n",
    "counter_left =0\n",
    "counter_center =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e123b089",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/4125034242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mCLOSED_EYES_FRAME\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mFONTS\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_COMPLEX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "FONTS =cv.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c21be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face bounder indices \n",
    "FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    "\n",
    "# lips indices for Landmarks\n",
    "LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n",
    "LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40534def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawColor(img, colors):\n",
    "    x, y = 0,10\n",
    "    w, h = 20, 30\n",
    "    \n",
    "    for color in colors:\n",
    "        x += w+5 \n",
    "        # y += 10 \n",
    "        cv.rectangle(img, (x-6, y-5 ), (x+w+5, y+h+5), (10, 50, 10), -1)\n",
    "        cv.rectangle(img, (x, y ), (x+w, y+h), color, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae77285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorBackgroundText(img, text, font, fontScale, textPos, textThickness=1,textColor=(0,255,0), bgColor=(0,0,0), pad_x=3, pad_y=3):\n",
    "    (t_w, t_h), _= cv.getTextSize(text, font, fontScale, textThickness) # getting the text size\n",
    "    x, y = textPos\n",
    "    cv.rectangle(img, (x-pad_x, y+ pad_y), (x+t_w+pad_x, y-t_h-pad_y), bgColor,-1) # draw rectangle \n",
    "    cv.putText(img,text, textPos,font, fontScale, textColor,textThickness ) # draw in text\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0465a6",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "id": "7d55a787",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\anaconda\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: mediapipe in c:\\anaconda\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anaconda\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sms studio\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (0.12.0)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\sms studio\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (3.17.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\anaconda\\lib\\site-packages (from mediapipe) (4.5.5.62)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\anaconda\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sms studio\\appdata\\roaming\\python\\python39\\site-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n"
     ]
    }
   ],
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "source": [
    "!pip install opencv-python mediapipe"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 9,
   "id": "5ab0183c",
=======
   "execution_count": 61,
   "id": "fc28437f",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import pygame \n",
    "from pygame import mixer \n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 10,
   "id": "e05e469b",
=======
   "execution_count": null,
   "id": "8b046c96",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 11,
   "id": "46845014",
=======
   "execution_count": null,
   "id": "e2e8e99a",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD:Test2Try.ipynb
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db960b3",
=======
   "cell_type": "markdown",
   "id": "d688b065",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "source": [
    "# _Create Functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 13,
   "id": "8b154e23",
=======
   "execution_count": 62,
   "id": "2711ac56",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark detection function \n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    # list[(x,y), (x,y)....]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw :\n",
    "        [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "\n",
    "    # returning the list of tuples for each landmarks \n",
    "    return mesh_coord"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 14,
   "id": "8a65da6b",
=======
   "execution_count": 63,
   "id": "f36b0b12",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclaidean distance \n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 15,
   "id": "612821c7",
=======
   "execution_count": 64,
   "id": "e9fa8af7",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blinking Ratio\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "\n",
    "    reRatio = rhDistance/rvDistance\n",
    "    leRatio = lhDistance/lvDistance\n",
    "\n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 16,
   "id": "df9e1013",
=======
   "execution_count": 65,
   "id": "a8050d96",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eyes Extrctor function,\n",
    "def eyesExtractor(img, right_eye_coords, left_eye_coords):\n",
    "    # converting color image to  scale image \n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # getting the dimension of image \n",
    "    dim = gray.shape\n",
    "\n",
    "    # creating mask from gray scale dim\n",
    "    mask = np.zeros(dim, dtype=np.uint8)\n",
    "\n",
    "    # drawing Eyes Shape on mask with white color \n",
    "    cv.fillPoly(mask, [np.array(right_eye_coords, dtype=np.int32)], 255)\n",
    "    cv.fillPoly(mask, [np.array(left_eye_coords, dtype=np.int32)], 255)\n",
    "\n",
    "    # showing the mask \n",
    "    # cv.imshow('mask', mask)\n",
    "    \n",
    "    # draw eyes image on mask, where white shape is \n",
    "    eyes = cv.bitwise_and(gray, gray, mask=mask)\n",
    "    # change black color to gray other than eys \n",
    "    # cv.imshow('eyes draw', eyes)\n",
    "    eyes[mask==0]=155\n",
    "    \n",
    "    # getting minium and maximum x and y  for right and left eyes \n",
    "    # For Right Eye \n",
    "    r_max_x = (max(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_min_x = (min(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_max_y = (max(right_eye_coords, key=lambda item : item[1]))[1]\n",
    "    r_min_y = (min(right_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # For LEFT Eye\n",
    "    l_max_x = (max(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_min_x = (min(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_max_y = (max(left_eye_coords, key=lambda item : item[1]))[1]\n",
    "    l_min_y = (min(left_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # croping the eyes from mask \n",
    "    cropped_right = eyes[r_min_y: r_max_y, r_min_x: r_max_x]\n",
    "    cropped_left = eyes[l_min_y: l_max_y, l_min_x: l_max_x]\n",
    "\n",
    "    # returning the cropped eyes \n",
    "    return cropped_right, cropped_left"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 17,
   "id": "a3a5d8c1",
=======
   "execution_count": 66,
   "id": "d4f3079f",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eyes Postion Estimator \n",
    "def positionEstimator(cropped_eye):\n",
    "    # getting height and width of eye \n",
    "    h, w =cropped_eye.shape\n",
    "    \n",
    "    # remove the noise from images\n",
    "    gaussain_blur = cv.GaussianBlur(cropped_eye, (9,9),0)\n",
    "    median_blur = cv.medianBlur(gaussain_blur, 3)\n",
    "\n",
    "    # applying thrsholding to convert binary_image\n",
    "    ret, threshed_eye = cv.threshold(median_blur, 130, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    # create fixd part for eye with \n",
    "    piece = int(w/3) \n",
    "\n",
    "    # slicing the eyes into three parts \n",
    "    right_piece = threshed_eye[0:h, 0:piece]\n",
    "    center_piece = threshed_eye[0:h, piece: piece+piece]\n",
    "    left_piece = threshed_eye[0:h, piece +piece:w]\n",
    "    \n",
    "    # calling pixel counter function\n",
    "    eye_position, color = pixelCounter(right_piece, center_piece, left_piece)\n",
    "\n",
    "    return eye_position, color "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 18,
   "id": "35f1005d",
=======
   "execution_count": 67,
   "id": "561b1740",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pixel counter function \n",
    "def pixelCounter(first_piece, second_piece, third_piece):\n",
    "    # counting black pixel in each part \n",
    "    right_part = np.sum(first_piece==0)\n",
    "    center_part = np.sum(second_piece==0)\n",
    "    left_part = np.sum(third_piece==0)\n",
    "    # creating list of these values\n",
    "    eye_parts = [right_part, center_part, left_part]\n",
    "\n",
    "    # getting the index of max values in the list \n",
    "    max_index = eye_parts.index(max(eye_parts))\n",
    "    pos_eye ='' \n",
    "    if max_index==0:\n",
    "        pos_eye=\"RIGHT\"\n",
    "        color=[BLACK, GREEN]\n",
    "    elif max_index==1:\n",
    "        pos_eye = 'CENTER'\n",
    "        color = [YELLOW, PINK]\n",
    "    elif max_index ==2:\n",
    "        pos_eye = 'LEFT'\n",
    "        color = [GRAY, YELLOW]\n",
    "    else:\n",
    "        pos_eye=\"Closed\"\n",
    "        color = [GRAY, YELLOW]\n",
    "    return pos_eye, color"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 19,
   "id": "57f2896b",
=======
   "execution_count": 68,
   "id": "afa3f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# styled color function \n",
    "def colorBackgroundText(img, text, font, fontScale, textPos, textThickness=1,textColor=(0,255,0), bgColor=(0,0,0), pad_x=3, pad_y=3):\n",
    "    \"\"\"\n",
    "    Draws text with background, with  control transparency\n",
    "    @param img:(mat) which you want to draw text\n",
    "    @param text: (string) text you want draw\n",
    "    @param font: fonts face, like FONT_HERSHEY_COMPLEX, FONT_HERSHEY_PLAIN etc.\n",
    "    @param fontScale: (double) the size of text, how big it should be.\n",
    "    @param textPos: tuple(x,y) position where you want to draw text\n",
    "    @param textThickness:(int) fonts weight, how bold it should be\n",
    "    @param textPos: tuple(x,y) position where you want to draw text\n",
    "    @param textThickness:(int) fonts weight, how bold it should be.\n",
    "    @param textColor: tuple(BGR), values -->0 to 255 each\n",
    "    @param bgColor: tuple(BGR), values -->0 to 255 each\n",
    "    @param pad_x: int(pixels)  padding of in x direction\n",
    "    @param pad_y: int(pixels) 1 to 1.0 (), controls transparency of  text background \n",
    "    @return: img(mat) with draw with background\n",
    "    \"\"\"\n",
    "    (t_w, t_h), _= cv.getTextSize(text, font, fontScale, textThickness) # getting the text size\n",
    "    x, y = textPos\n",
    "    cv.rectangle(img, (x-pad_x, y+ pad_y), (x+t_w+pad_x, y-t_h-pad_y), bgColor,-1) # draw rectangle \n",
    "    cv.putText(img,text, textPos,font, fontScale, textColor,textThickness ) # draw in text\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd695a2d",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/2075983310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap_face_mesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_mesh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# camera object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcamera\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "def textWithBackground(img, text, font, fontScale, textPos, textThickness=1,textColor=(0,255,0), bgColor=(0,0,0), pad_x=3, pad_y=3, bgOpacity=0.5):\n",
    "    \"\"\"\n",
    "    Draws text with background, with  control transparency\n",
    "    @param img:(mat) which you want to draw text\n",
    "    @param text: (string) text you want draw\n",
    "    @param font: fonts face, like FONT_HERSHEY_COMPLEX, FONT_HERSHEY_PLAIN etc.\n",
    "    @param fontScale: (double) the size of text, how big it should be.\n",
    "    @param textPos: tuple(x,y) position where you want to draw text\n",
    "    @param textThickness:(int) fonts weight, how bold it should be\n",
    "    @param textPos: tuple(x,y) position where you want to draw text\n",
    "    @param textThickness:(int) fonts weight, how bold it should be.\n",
    "    @param textColor: tuple(BGR), values -->0 to 255 each\n",
    "    @param bgColor: tuple(BGR), values -->0 to 255 each\n",
    "    @param pad_x: int(pixels)  padding of in x direction\n",
    "    @param pad_y: int(pixels) 1 to 1.0 (), controls transparency of  text background \n",
    "    @return: img(mat) with draw with background\n",
    "    \"\"\"\n",
    "    (t_w, t_h), _= cv.getTextSize(text, font, fontScale, textThickness) # getting the text size\n",
    "    x, y = textPos\n",
    "    overlay = img.copy() # coping the image\n",
    "    cv.rectangle(overlay, (x-pad_x, y+ pad_y), (x+t_w+pad_x, y-t_h-pad_y), bgColor,-1) # draw rectangle \n",
    "    new_img = cv.addWeighted(overlay, bgOpacity, img, 1 - bgOpacity, 0) # overlaying the rectangle on the image.\n",
    "    cv.putText(new_img,text, textPos,font, fontScale, textColor,textThickness ) # draw in text\n",
    "    img = new_img\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42ed4f",
   "metadata": {},
   "source": [
    "# _Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bde21d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_face_mesh = mp.solutions.face_mesh # mediapipe.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50cff5e",
   "metadata": {},
   "source": [
    "# _Variables Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef644c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables \n",
    "frame_counter =0\n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "start_voice= False\n",
    "counter_right=0\n",
    "counter_left =0\n",
    "counter_center =0 \n",
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "FONTS =cv.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f78ee990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face bounder indices \n",
    "FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    " \n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "380f8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors \n",
    "# values =(blue, green, red) opencv accepts BGR values not RGB\n",
    "BLACK = (0,0,0)\n",
    "WHITE = (255,255,255)\n",
    "BLUE = (255,0,0)\n",
    "RED = (0,0,255)\n",
    "CYAN = (255,255,0)\n",
    "YELLOW =(0,255,255)\n",
    "MAGENTA = (255,0,255)\n",
    "GRAY = (128,128,128)\n",
    "GREEN = (0,255,0)\n",
    "PURPLE = (128,0,128)\n",
    "ORANGE = (0,165,255)\n",
    "PINK = (147,20,255)\n",
    "points_list =[(200, 300), (150, 150), (400, 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14bde379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # video Recording setup \n",
    "# fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv.VideoWriter('output21.mp4', fourcc, 30.0, (img_width, img_hieght))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2356790",
   "metadata": {},
   "source": [
    "# _ Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d725d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 960\n"
     ]
    }
   ],
   "source": [
    "# camera object \n",
    "cap = cv.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "img = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "img_hieght, img_width = img.shape[:2]\n",
    "print(img_hieght, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "635a221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with map_face_mesh.FaceMesh(min_detection_confidence =0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # starting time here \n",
    "    start_time = time.time()\n",
    "    # starting Video loop here.\n",
    "    while True:\n",
    "        frame_counter +=1 # frame counter\n",
    "        ret, frame = cap.read() # getting frame from camera \n",
    "        if not ret: \n",
    "            break # no more frames break\n",
    "        #  resizing frame\n",
    "        \n",
    "        frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "        frame_height, frame_width= frame.shape[:2]\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "        results  = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_coords = landmarksDetection(frame, results, False)\n",
    "            ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "            colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, PINK, YELLOW)\n",
    "\n",
    "            if ratio >5.5:\n",
    "                CEF_COUNTER +=1\n",
    "                colorBackgroundText(frame,  f'Blink', FONTS, 1.7, (int(frame_height/2), 100), 2, YELLOW, pad_x=6, pad_y=6, )\n",
    "\n",
    "            else:\n",
    "                if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                    TOTAL_BLINKS +=1\n",
    "                    CEF_COUNTER =0\n",
    "           \n",
    "            colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n",
    "            \n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, GREEN, 1, cv.LINE_AA)\n",
    "            cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, GREEN, 1, cv.LINE_AA)\n",
    "\n",
    "            # Blink Detector Counter Completed\n",
    "            right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "            left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "            crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "            # cv.imshow('right', crop_right)\n",
    "            # cv.imshow('left', crop_left)\n",
    "            eye_position_right, color = positionEstimator(crop_right)\n",
    "            colorBackgroundText(frame, f'R: {eye_position_right}', FONTS, 1.0, (40, 220), 2, color[0], color[1], 8, 8)\n",
    "            eye_position_left, color = positionEstimator(crop_left)\n",
    "            colorBackgroundText(frame, f'L: {eye_position_left}', FONTS, 1.0, (40, 320), 2, color[0], color[1], 8, 8)\n",
    "            \n",
    "            # Starting Indicator \n",
    "            if eye_position_right==\"RIGHT\" and  counter_right<2:\n",
    "                # starting counter \n",
    "                counter_right+=1\n",
    "                # resetting counters \n",
    "                counter_center=0\n",
    "                counter_left=0\n",
    "\n",
    "\n",
    "            if eye_position_right==\"CENTER\"  and counter_center <2:\n",
    "                # starting Counter \n",
    "                counter_center +=1\n",
    "                # resetting counters \n",
    "                counter_right=0\n",
    "                counter_left=0\n",
    "                \n",
    "            \n",
    "            if eye_position_right==\"LEFT\"  and counter_left<2: \n",
    "                counter_left +=1\n",
    "                # resetting counters \n",
    "                counter_center=0\n",
    "                counter_right=0\n",
    "\n",
    "\n",
    "\n",
    "        # calculating  frame per seconds FPS\n",
    "        end_time = time.time()-start_time\n",
    "        fps = frame_counter/end_time\n",
    "        \n",
    "\n",
    "        frame =textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n",
    "        # writing image for thumbnail drawing shape\n",
    "        # cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n",
    "        # wirting the video for demo purpose \n",
    "        # out.write(frame)\n",
    "        cv.imshow('frame', frame)\n",
    "        key = cv.waitKey(2)\n",
    "        if key==ord('q') or key ==ord('Q'):\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "    camera.release()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Test2Try.ipynb
   "execution_count": 20,
   "id": "2d0075c5",
=======
   "execution_count": 96,
   "id": "b1f87df0",
>>>>>>> aea495e2ea1e521994dcc06d04b77c2c5b305af4:resources/Get video values (EYE_TOTAL_BLINKS, EYE_COUNTER_LEFT, EYE_COUNTER_RIGHT)..ipynb
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1817700874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "cv.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d65af4",
   "metadata": {},
   "source": [
    "# ~Get video values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "385fdc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_BLINKS 13\n",
      "counter_right 0\n",
      "counter_left 1\n"
     ]
    }
   ],
   "source": [
    "print(\"TOTAL_BLINKS\",TOTAL_BLINKS)\n",
    "print(\"counter_right\",counter_right)\n",
    "print(\"counter_left\",counter_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7717b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
